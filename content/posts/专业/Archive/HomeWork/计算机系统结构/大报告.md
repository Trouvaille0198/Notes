---
draft: true
---

![image-20220530102045985](https://markdown-1303167219.cos.ap-shanghai.myqcloud.com/image-20220530102045985.png)

![image-20220530102146644](https://markdown-1303167219.cos.ap-shanghai.myqcloud.com/image-20220530102146644.png)

# 大报告

在系统结构层次上，优化计算机系统的指令执行速度的措施有很多，本报告主要介绍了指令优化、流水线结构和并行计算三种技术措施，并且编写了 OpenMP C++ 程序，以体现并行技术带来的优化效果。

## 指令优化

一条指令对应着机器语言的一条语句。高级语言程序的语句通常要被翻译为多条机器指令来执行。对指令系统的优化，直接影响到了计算机系统的指令执行速度。

### 指令集的改进

CISC（Complex Instruction Set Computer）指令集提供了大量复杂的指令，以缩短其与高级语言之间的语义差距，提高了操作系统的运行效率。一条指令完成了数条原始机器指令的功能，从而间接提高了指令的执行速度。

不过随着复杂指令的不断增加，CPU 的结构也趋于复杂，这造成了编译程序上的极大困难，过犹不及。RISC（Reduced Instruction Set Computer）指令集则更为精简，仅仅保留了那些使用频率很高的少量指令，降低了复杂性，更加适合日益强大的 CPU 的需求。

### 针对高级语言的优化

由高级语言编写的程序需要被翻译成机器语言之后才能被计算机所执行。所以，针对指令系统的优化很大一部分是对高级语言一些固有特性的指令层面实现。条件跳转指令的出现对应着高级语言中的条件判断语句 if；call 和 ret 指令针对一些程序中出现的嵌套结构。这些例子都充分体现出指令系统针对高级语言特性所进行的专门优化。

### 针对特殊场景的优化

现代计算机系统的分工化、专业化特征日益明显，针对特殊场景下的指令优化，已经成为了常态。比如计算机视觉库 OpenCV 的执行速度就可以被 RISC-V 提供的矢量寄存器和相应的矢量指令优化。

## 流水线结构

流水线结构（Pipeline Architecture）是一种任务分解技术，它旨在提高指令的并行性，从而加快指令的解释过程。

### 重叠方式

解释一条指令的通常方法是：取出指令，将指令放入指令分析器中进行解析，将指令放入执行部件中进行执行。在传统的计算机结构中，这一系列步骤串行完成，指令分析器部件具有大量的空闲时间，利用明显不充分。

采用重叠方式解释指令的核心逻辑是：在第 n 条指令执行时，同时让第 n+1 条指令装入指令分析器中进行分析，这样可以将串行方式变为一定程度上的并行方式，加快了指令执行速度。

重叠方式需要一定的硬件支持，如指令缓冲寄存器，在执行第 n 条指令时，它可以存储的第 n+1 条指令信息。

### 先行控制

重叠方式带来的问题是：难以做到分析与执行时间完全相等，会造成分析与执行部件的等待现象。

为了让分析部件持续地工作，先行控制机制引入了指令栈等硬件结构，它支持对接下来的数个指令进行预取、预处理，保证了分析过程连续不停顿。

### 流水线技术

流水线技术是对重叠方式和先行控制的进一步优化与延伸，这种技术将指令的解释过程进一步细化为“取指”、“译码”、“取操作数”、“执行”四个过程，每个过程都用各自独立的硬件部件完成。

流水线技术对于硬件要求很高，因为每一个细分的步骤，都需要一个专门的功能部件去实现。

指令解释过程的细分可以让指令的并行运行力度达到最大化，大大提高了计算机系统的指令执行速度。

## 并行计算

随着多核处理机的普及，并行计算的发展也相当快速。狭义的并行计算指利用 CPU 多核同时执行，是空间意义上的并发。而广义的并行计算还包括上述的流水线结构，属于时间上的并发。

OpenMP 和 MPICH 技术针对多线程与分布式多进程分别提供了高效易学的支持。

### OpenMP

OpenMP（Open Multiprocessing）是一种实现多线程的编程模型，它为高级语言提供了一套指导性注释语法，可以轻松地让串行代码实现并行功能。

OpenMP 采用共享内存模型，保证每个线程能够读取和改写公共部分的数据。并且使用 fork-join 模型，在遇到并行区域时使用 FORK 功能，将单一的主线程分裂成若干个并行子线程进行并行运算；当完成并行区域中的语句后，子线程又执行 JOIN 功能，释放内核并退出。

### MPICH

MPI（Message Passing Interface）是一个公共的消息传递库，它负责在并行程序的各个任务（通常是不同主机上的单一进程）之间的消息传递和内容同步。MPICH 是 MPI 的一类标准实现。它被更多地用在计算机集群系统和分布式系统中。

MPICH 广泛使用了发送和接受消息的机制来完成不同主机在网络之间的信息传递。

## Neon

ARM NEON 是一个单指令多数据（SIMD）架构的扩展，Neon 在视频处理、图像识别、语音识别功能的计算能力相当突出，并且被多种编码标准和 ARM 处理器支持。

Neon 的技术核心是 Neon 单元，它完全集成到 CPU 中，并且使用独立的寄存器，可以与 CPU 共享缓存资源，与传统的硬件加速器方案相比，降低了功耗，并且减少了面积。

## OpenMP 编程

我使用 OpenMP 提供的 #pragma 注释语法，针对归并排序算法进行了多线程并行计算优化

归并排序需要调用自身进行递归运算，这时使用一个独立的子线程来运行递归部分可以加快速度

```cpp
#include <iostream>
#include <vector>
#include <omp.h>
using namespace std;

// g++ -fopenmp  merge_sort.cpp -o merge_sort.o
vector<long> merge(const vector<long> &l, const vector<long> &r)
// 两个数组升序合并
{
    vector<long> res;
    int i = 0, j = 0;

    while (i < l.size() && j < r.size())
    {
        if (l[i] < r[j])
            res.push_back(l[i++]);
        else
            res.push_back(r[j++]);
    }

    // 添加某一数组的剩余部分
    while (i < l.size())
        res.push_back(l[i++]);

    while (j < r.size())
        res.push_back(r[j++]);

    return res;
}

vector<long> mergeSortParallel(vector<long> &num, int threadNum)
// 归并排序 并行执行
{
    if (num.size() == 1)
        return num;

    std::vector<long>::iterator middle = num.begin() + (num.size() / 2);
    vector<long> l(num.begin(), middle);
    vector<long> r(middle, num.end());

    if (threadNum > 1)
    {
#pragma omp parallel sections
        {
#pragma omp section
            {
                l = mergeSortParallel(l, threadNum / 2); // 分配一半线程执行此递归程序
            }
#pragma omp section
            {
                r = mergeSortParallel(r, threadNum - threadNum / 2); // 分配剩余线程
            }
        }
    }
    else
    {
        l = mergeSortParallel(l, 1);
        r = mergeSortParallel(r, 1);
    }

    return merge(l, r);
}

vector<long> mergeSortSerial(vector<long> &num)
// 归并排序 线性执行
{
    if (num.size() == 1)
        return num;

    std::vector<long>::iterator middle = num.begin() + (num.size() / 2);
    vector<long> l(num.begin(), middle);
    vector<long> r(middle, num.end());

    l = mergeSortSerial(l);
    r = mergeSortSerial(r);

    return merge(l, r);
}

int main()
{
    double start, end;
    double parallelDuration, serialDuration;
    cout << "总共有" << omp_get_max_threads() << "个线程" << endl;
    vector<long> a(50000000), b(50000000);
    for (long i = 0; i < 50000000; ++i)
    {
        int randInt = rand() % 10;
        a[i] = randInt;
        b[i] = randInt;
    }

    start = omp_get_wtime();
    b = mergeSortSerial(b);
    end = omp_get_wtime();
    serialDuration = end - start;
    cout << "串行计算共耗时" << serialDuration << "s." << endl;

    start = omp_get_wtime();
    a = mergeSortParallel(a, omp_get_max_threads());
    end = omp_get_wtime();
    parallelDuration = end - start;
    cout << "并行计算共耗时" << parallelDuration << "s." << endl;

    cout << "运行加速比为" << serialDuration / parallelDuration << endl;
}
```

OpenMP 提供了方便的注释语法来帮助我们编写稳定的并行程序。omp_get_max_threads() 函数显示了当前计算机可以拥有的最大线程数，相当于主机的 CPU 核数；#pragma omp parallel sections 设置并行处理区域，在区域内的 #pragma omp section 则指定线程执行的部分，系统会自动分配空闲的线程运算这些部分。

我生成了若干组，得到串行计算和并行计算所耗费的时间，并且计算了加速比：

| 数组元素个数 | 串行耗时/s | 并行耗时/s | 加速比 |
| ------------ | ---------- | ---------- | ------ |
| 500000       | 0.90       | 0.54       | 1.66   |
| 1000000      | 1.80       | 1.30       | 1.39   |
| 5000000      | 9.64       | 5.32       | 1.81   |
| 10000000     | 19.55      | 10.83      | 1.81   |
| 50000000     | 103.62     | 55.76      | 1.81   |

下图是生成 50000000 个数组元素和 10000000 个数组元素时的程序运行情况：

![image-20220530210334762](https://markdown-1303167219.cos.ap-shanghai.myqcloud.com/image-20220530210334762.png)

![image-20220530191857624](https://markdown-1303167219.cos.ap-shanghai.myqcloud.com/image-20220530191857624.png)

