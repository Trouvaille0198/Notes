# 一、Beautiful Soup

## 1.1 简介

Beautiful Soup就是Python的一个HTML或XML的解析库，可以用它来方便地从网页中提取数据、

官方解释

1. Beautiful Soup提供一些简单的、Python式的函数来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。

2. Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为UTF-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时你仅仅需要说明一下原始编码方式就可以了。

3. Beautiful Soup已成为和lxml、html6lib一样出色的Python解释器，为用户灵活地提供不同的解析策略或强劲的速度。

 ## 1.2 解析器

Beautiful Soup在解析时实际上依赖解析器，它除了支持Python标准库中的HTML解析器外，还支持一些第三方解析器（比如lxml）

### 1.2.1 支持的解析器

![image-20201206195341754](https://trou.oss-cn-shanghai.aliyuncs.com/img/image-20201206195341754.png)

通过以上对比可以看出，lxml解析器有解析HTML和XML的功能，而且速度快，容错能力强，所以推荐使用它

### 1.2.2 基本操作

```python
from bs4 import BeautifulSoup
html = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title" name="dromouse"><b>The Dormouse's story</b></p>
<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1"><!-- Elsie --></a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>
<p class="story">...</p>
"""
soup = BeautifulSoup(html, 'lxml')
print(soup.prettify())
print(soup.title.string)
```

步骤

1. 首先声明变量html，它是一个HTML字符串。（不完整，body和html节点都没有闭合）

2. 将它当作第一个参数传给BeautifulSoup对象，该对象的第二个参数为解析器的类型（这里使用lxml），此时就完成了BeaufulSoup对象的初始化。

3. 然后，将这个对象赋值给soup变量。

4. 调用soup的各个方法和属性解析这串HTML代码

   - 调用prettify()方法。这个方法可以把要解析的字符串以标准的缩进格式输出（对于不标准的HTML字符串BeautifulSoup，可以自动更正格式，但这一步不是由prettify()方法做的，而是在初始化BeautifulSoup时就完成了）

   - 调用soup.title.string，这实际上是输出HTML中title节点的文本内容。所以，soup.title可以选出HTML中的title节点，再调用string属性就可以得到里面的文本了

## 1.3 节点选择器

直接调用节点的名称就可以选择节点元素，再调用string属性就可以得到节点内的文本了，这种选择方式速度非常快。如果单个节点结构层次非常清晰，可以选用这种方式来解析

### 1.3.1 选择元素

```python
from bs4 import BeautifulSoup
html = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title" name="dromouse"><b>The Dormouse's story</b></p>
<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1"><!-- Elsie --></a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>
<p class="story">...</p>
"""
soup = BeautifulSoup(html, 'lxml')
print(soup.title)
print(type(soup.title))
print(soup.title.string)
print(soup.head)
print(soup.p)
```

输出

```HTML
<title>The Dormouse's story</title>
<class 'bs4.element.Tag'>
The Dormouse's story
<head><title>The Dormouse's story</title></head>
<p class="title" name="dromouse"><b>The Dormouse's story</b></p>
```

步骤

1. 打印输出title节点的选择结果，输出结果正是title节点+文字内容
2. 输出它的类型，是`bs4.element.Tag`类型，这是Beautiful Soup中一个重要的数据结构。经过选择器选择后，选择结果都是这种Tag类型。Tag具有一些属性，比如string属性，调用该属性，可以得到节点的文本内容，所以接下来的输出结果正是节点的文本内容
3. 输出head节点+其内部的所有内容
4. 最后选择了p节点。输出第一个p节点的内容（当有多个节点时，这种选择方式只会选择到第一个匹配的节点，其他的后面节点都会忽略）

### 1.3.2 提取信息

#### 1.3.2.1 获取名称（name）

```python
print(soup.title.name)
```

输出

```
title
```

#### 1.3.2.2 获取属性（attrs）

```python
print(soup.p.attrs)
print(soup.p.attrs['name'])
```

输出

```
{'class': ['title'], 'name': 'dromouse'}
dromouse
```

attrs的返回结果是字典形式，它把选择的节点的所有属性和属性值组合成一个字典

要获取name属性，就可以通过attrs['name']来得到

可以不用写attrs，直接在节点元素后面加中括号，传入属性名

```python
print(soup.p['name'])
print(soup.p['class'])
```

输出

```
dromouse
['title']
```

有的返回结果是字符串，有的返回结果是字符串组成的列表。比如，name属性的值是唯一的，返回的结果就是单个字符串。而对于class，一个节点元素可能有多个class，所以返回的是列表

#### 1.3.2.3 获取内容

```python
print(soup.p.string)
```

输出

```
The Dormouse's story
```

#### 1.3.2.4 嵌套选择

```python
from bs4 import BeautifulSoup
html = """
<html><head><title>The Dormouse's story</title></head>
<body>
"""
soup = BeautifulSoup(html, 'lxml')
print(soup.head.title)
print(type(soup.head.title))
print(soup.head.title.string)
```

输出

````html
<title>The Dormouse's story</title>
<class 'bs4.element.Tag'>
The Dormouse's story
````

### 1.3.3 关联选择

在做选择的时候，有时候不能做到一步就选到想要的节点元素，需要先选中某一个节点元素，然后以它为基准再选择它的子节点、父节点、兄弟节点等

#### 1.3.3.1 子节点和子孙节点

##### 1）调用contents属性，得到直接子节点的列表

```python
from bs4 import BeautifulSoup
html = """
<html>
    <head>
        <title>The Dormouse's story</title>
    </head>
    <body>
        <p class="story">
            Once upon a time there were three little sisters; and their names were
            <a href="http://example.com/elsie" class="sister" id="link1">
                <span>Elsie</span>
            </a>
            <a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> 
            and
            <a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>
            and they lived at the bottom of a well.
        </p>
        <p class="story">...</p>
"""
soup = BeautifulSoup(html, 'lxml')
print(soup.p.contents)
```

输出

```html
['\n            Once upon a time there were three little sisters; and their names were\n            ', <a class="sister" href="http://example.com/elsie" id="link1">
<span>Elsie</span>
</a>, '\n', <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>, ' \n            and\n            ', <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>, '\n            and they lived at the bottom of a well.\n        ']
```

contents属性得到的结果是直接子节点的列表

##### 2）调用children属性，获取子节点

```python
soup = BeautifulSoup(html, 'lxml')
print(soup.p.children)
for i, child in enumerate(soup.p.children):
    print(i, child)
```

##### 3）调用descendants属性，获取所有子孙节点

```python
soup = BeautifulSoup(html, 'lxml')
print(soup.p.descendants)
for i, child in enumerate(soup.p.descendants):
    print(i, child)
```

#### 1.3.3.2 父节点和祖先节点

##### 1）调用parent属性，获取某个节点元素的直接父节点

```python
from bs4 import BeautifulSoup
html = """
<html>
    <head>
        <title>The Dormouse's story</title>
    </head>
    <body>
        <p class="story">
            Once upon a time there were three little sisters; and their names were
            <a href="http://example.com/elsie" class="sister" id="link1">
                <span>Elsie</span>
            </a>
        </p>
        <p class="story">...</p>
"""
soup = BeautifulSoup(html, 'lxml')
print(soup.a.parent)
```

输出

```html
<p class="story">
            Once upon a time there were three little sisters; and their names were
            <a class="sister" href="http://example.com/elsie" id="link1">
<span>Elsie</span>
</a>
</p>
```

输出结果便是p节点及其内部的内容。

##### 2）调用parents属性，获取某个节点元素的所有父节点

```python
from bs4 import BeautifulSoup
html = """
<html>
    <body>
        <p class="story">
            <a href="http://example.com/elsie" class="sister" id="link1">
                <span>Elsie</span>
            </a>
        </p>
"""
soup = BeautifulSoup(html, 'lxml')
print(type(soup.a.parents))
print(list(enumerate(soup.a.parents)))
```

输出

```html
<class 'generator'>
[(0, <p class="story">
<a class="sister" href="http://example.com/elsie" id="link1">
<span>Elsie</span>
</a>
</p>), (1, <body>
<p class="story">
<a class="sister" href="http://example.com/elsie" id="link1">
<span>Elsie</span>
</a>
</p>
</body>), (2, <html>
<body>
<p class="story">
<a class="sister" href="http://example.com/elsie" id="link1">
<span>Elsie</span>
</a>
</p>
</body></html>), (3, <html>
<body>
<p class="story">
<a class="sister" href="http://example.com/elsie" id="link1">
<span>Elsie</span>
</a>
</p>
</body></html>)]
```

返回结果是生成器类型。这里用列表输出了它的索引和内容，而列表中的元素就是a节点的祖先节点

##### 3）兄弟节点

```python
from bs4 import BeautifulSoup
html = """
<html>
    <body>
        <p class="story">
            Once upon a time there were three little sisters; and their names were
            <a href="http://example.com/elsie" class="sister" id="link1">
                <span>Elsie</span>
            </a>
            Hello
            <a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> 
            and
            <a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>
            and they lived at the bottom of a well.
        </p>
"""
soup = BeautifulSoup(html, 'lxml')
print('Next Sibling', soup.a.next_sibling)
print('Prev Sibling', soup.a.previous_sibling)
print('Next Siblings', list(enumerate(soup.a.next_siblings)))
print('Prev Siblings', list(enumerate(soup.a.previous_siblings)))
```

输出

```html
Next Sibling
            Hello

Prev Sibling
            Once upon a time there were three little sisters; and their names were

Next Siblings [(0, '\n            Hello\n            '), (1, <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>), (2, ' \n            and\n            '), (3, <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>), (4, '\n            and they lived at the bottom of a well.\n        ')]
Prev Siblings [(0, '\n            Once upon a time there were three little sisters; and their names were\n            ')]
```

这里调用了4个属性

1. `next_sibling`和`previous_sibling`分别获取节点的下一个和上一个兄弟元素
2. `next_siblings`和`previous_siblings`则分别返回所有前面和后面的兄弟节点的生成器

##### 4）提取节点信息举例

````python
print(list(soup.a.parents)[0].attrs['class'])
print(soup.a.next_sibling.string)
````

## 1.4 方法选择器

### 1.4.1 find_all()

查询所有符合条件的元素。给它传入一些属性或文本，就可以得到符合条件的元素，它的功能十分强大

API：`find_all(name , attrs , recursive , text , **kwargs)`

#### 1.4.1.1 name

```python
from bs4 import BeautifulSoup
html = '''
<div class="panel">
    <div class="panel-heading">
        <h4>Hello</h4>
    </div>
    <div class="panel-body">
        <ul class="list" id="list-1">
            <li class="element">Foo</li>
            <li class="element">Bar</li>
            <li class="element">Jay</li>
        </ul>
        <ul class="list list-small" id="list-2">
            <li class="element">Foo</li>
            <li class="element">Bar</li>
        </ul>
    </div>
</div>
'''
soup = BeautifulSoup(html, 'lxml')
print(soup.find_all(name='ul'))
print(type(soup.find_all(name='ul')[0]))
```

输出

```HTML
[<ul class="list" id="list-1">
<li class="element">Foo</li>
<li class="element">Bar</li>
<li class="element">Jay</li>
</ul>, <ul class="list list-small" id="list-2">
<li class="element">Foo</li>
<li class="element">Bar</li>
</ul>]
<class 'bs4.element.Tag'>
```

查询所有ul节点，返回结果是列表类型，长度为2，每个元素依然都是bs4.element.Tag类型

可以进行嵌套查询。还是同样的文本，这里查询出所有ul节点后，再继续查询其内部的li节点

```python
for ul in soup.find_all(name='ul'):
    print(ul.find_all(name='li'))
```

输出

```
[<li class="element">Foo</li>, <li class="element">Bar</li>, <li class="element">Jay</li>]
[<li class="element">Foo</li>, <li class="element">Bar</li>]
```

#### 1.4.1.2 attrs

```python
from bs4 import BeautifulSoup
html = '''
<div class="panel">
    <div class="panel-heading">
        <h4>Hello</h4>
    </div>
    <div class="panel-body">
        <ul class="list" id="list-1" name="elements">
            <li class="element">Foo</li>
            <li class="element">Bar</li>
            <li class="element">Jay</li>
        </ul>
        <ul class="list list-small" id="list-2">
            <li class="element">Foo</li>
            <li class="element">Bar</li>
        </ul>
    </div>
</div>
'''
soup = BeautifulSoup(html, 'lxml')
print(soup.find_all(attrs={'id': 'list-1'}))
print(soup.find_all(attrs={'name': 'elements'}))
```

输出

```html
[<ul class="list" id="list-1" name="elements">
<li class="element">Foo</li>
<li class="element">Bar</li>
<li class="element">Jay</li>
</ul>]
[<ul class="list" id="list-1" name="elements">
<li class="element">Foo</li>
<li class="element">Bar</li>
<li class="element">Jay</li>
</ul>]
```

传入attrs参数，参数的类型是字典类型

得到的结果是列表形式

对于一些常用的属性，比如id和class等，我们可以不用attrs来传递

```python
print(soup.find_all(id='list-1'))
print(soup.find_all(class_='element'))
```

#### 1.4.1.3 text参数可用来匹配节点的文本，传入的形式可以是字符串，可以是正则表达式对象

```python
from bs4 import BeautifulSoup
import re
html = '''
<div class="panel">
    <div class="panel-body">
        <a>Hello, this is a link</a>
        <a>Hello, this is a link, too</a>
    </div>
</div>
'''
soup = BeautifulSoup(html, 'lxml')
print(soup.find_all(text=re.compile('link')))
```

输出

```
['Hello, this is a link', 'Hello, this is a link, too']
```

这里有两个a节点，其内部包含文本信息。这里在find_all()方法中传入text参数，该参数为正则表达式对象，结果返回所有匹配正则表达式的节点文本组成的列表

### 1.4.2 其他选择器

#### 1）find()

除了find_all()方法，还有find()方法，只不过后者返回的是单个元素，也就是第一个匹配的元素，而前者返回的是所有匹配的元素组成的列表

#### 2）find_parents()和find_parent()

前者返回所有祖先节点，后者返回直接父节点。

#### 3）find_next_siblings()和find_next_sibling()

前者返回后面所有的兄弟节点，后者返回后面第一个兄弟节点。

#### 4）find_previous_siblings()和find_previous_sibling()

前者返回前面所有的兄弟节点，后者返回前面第一个兄弟节点。

#### 5）find_all_next()和find_next()

前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点。

#### 6）find_all_previous()和find_previous()

前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点。

## 1.5 CSS选择器

使用CSS选择器时，只需要调用`select()`方法，传入相应的CSS选择器即可

```python
from bs4 import BeautifulSoup
html = '''
<div class="panel">
    <div class="panel-heading">
        <h4>Hello</h4>
    </div>
    <div class="panel-body">
        <ul class="list" id="list-1">
            <li class="element">Foo</li>
            <li class="element">Bar</li>
            <li class="element">Jay</li>
        </ul>
        <ul class="list list-small" id="list-2">
            <li class="element">Foo</li>
            <li class="element">Bar</li>
        </ul>
    </div>
</div>
'''
soup = BeautifulSoup(html, 'lxml')
print(soup.select('.panel .panel-heading'))
print(soup.select('ul li'))
print(soup.select('#list-2 .element'))
print(type(soup.select('ul')[0]))
```

输出

```html
[<div class="panel-heading">
<h4>Hello</h4>
</div>]
[<li class="element">Foo</li>, <li class="element">Bar</li>, <li class="element">Jay</li>, <li class="element">Foo</li>, <li class="element">Bar</li>]
[<li class="element">Foo</li>, <li class="element">Bar</li>]
<class 'bs4.element.Tag'>
```

这里我们用了3次CSS选择器，返回的结果均是符合CSS选择器的节点组成的列表。例如，select('ul li')则是选择所有ul节点下面的所有li节点，结果便是所有的li节点组成的列表。

### 1.5.1 `select()`方法同样支持嵌套选择

```python
soup = BeautifulSoup(html, 'lxml')
for ul in soup.select('ul'):
    print(ul.select('li'))
```

输出

```html
[<li class="element">Foo</li>, <li class="element">Bar</li>, <li class="element">Jay</li>]
[<li class="element">Foo</li>, <li class="element">Bar</li>]
```

这里正常输出了所有ul节点下所有li节点组成的列表

### 1.5.2 获取属性

节点类型是Tag类型，所以获取属性还可以用原来的方法。仍然是上面的HTML文本，这里尝试获取每个ul节点的id属性

```python
for ul in soup.select('ul'):
    print(ul['id'])
    print(ul.attrs['id'])
```

输出

```
list-1
list-1
list-2
list-2
```

直接传入中括号和属性名，以及通过attrs属性获取属性值，都可以成功

### 1.5.3 获取文本

要获取文本，当然也可以用前面所讲的string属性。此外，还有一个方法，那就是`get_text()`

```python
for li in soup.select('li'):
    print('Get Text:', li.get_text())
    print('String:', li.string)
```

输出

```
Get Text: Foo
String: Foo
Get Text: Bar
String: Bar
Get Text: Jay
String: Jay
Get Text: Foo
String: Foo
Get Text: Bar
String: Bar
```

# 二、pyquery

## 2.1 初始化

### 2.1.1 字符初始化

```python
from pyquery import PyQuery as pq
html = '''
<div>
    <ul>
         <li class="item-0">first item</li>
         <li class="item-1"><a href="link2.html">second item</a></li>
         <li class="item-0 active"><a href="link3.html"><span class="bold">third item</span></a></li>
         <li class="item-1 active"><a href="link4.html">fourth item</a></li>
         <li class="item-0"><a href="link5.html">fifth item</a></li>
     </ul>
 </div>
'''
doc = pq(html)
print(doc('li'))
```

输出

```html
<li class="item-0">first item</li>
<li class="item-1"><a href="link2.html">second item</a></li>
<li class="item-0 active"><a href="link3.html"><span class="bold">third item</span></a></li>
<li class="item-1 active"><a href="link4.html">fourth item</a></li>
<li class="item-0"><a href="link5.html">fifth item</a></li>
```

这里首先引入PyQuery这个对象，取别名为pq。然后声明了一个长HTML字符串，并将其当作参数传递给PyQuery类，这样就成功完成了初始化。接下来，将初始化的对象传入CSS选择器。在这个实例中，我们传入li节点，这样就可以选择所有的li节点

### 2.1.2 URL初始化

```python
from pyquery import PyQuery as pq
doc = pq(url='http://www.trouvaille0198.top/')
print(doc('title'))
```

输出

```html
<title itemprop="name">薯条鸭专业养殖基地 - 嚯</title>
```

这样的话，PyQuery对象会首先请求这个URL，然后用得到的HTML内容完成初始化，这其实就相当于用网页的源代码以字符串的形式传递给PyQuery类来初始化。

等效于

```python
doc = pq(requests.get('http://cuiqingcai.com').text)
```

### 2.1.3 文件初始化

还可以传递本地的文件名，此时将参数指定为filename即可

```python
from pyquery import PyQuery as pq
doc = pq(filename='demo.html')
print(doc('li'))
```

这里需要有一个本地HTML文件demo.html，其内容是待解析的HTML字符串。这样它会首先读取本地的文件内容，然后用文件内容以字符串的形式传递给PyQuery类来初始化